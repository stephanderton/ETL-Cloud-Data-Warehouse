{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Redshift Cluster\n",
    "**Using AWS Python SDK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "# import logging\n",
    "import mylib\n",
    "from mylib import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/test-20190527.log'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylib.log_file_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('===[  Inititate Cluster  ]===')\n",
    "logger.info(time.strftime('%Y-%m-%d  %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DWH, Cluster and DB Params from config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = 'dwh.cfg'\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open(CONFIG_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"\n",
    "    Load DWH Cluster and DB Params from config file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    DWH_CLUSTER_TYPE       = config['DWH']['DWH_CLUSTER_TYPE']\n",
    "    DWH_NUM_NODES          = config['DWH']['DWH_NUM_NODES']\n",
    "    DWH_NODE_TYPE          = config['DWH']['DWH_NODE_TYPE']\n",
    "    DWH_CLUSTER_IDENTIFIER = config['DWH']['DWH_CLUSTER_IDENTIFIER']\n",
    "    DWH_REGION             = config['DWH']['DWH_REGION']\n",
    "\n",
    "    HOST                   = config['CLUSTER']['HOST']\n",
    "    DB_NAME                = config['CLUSTER']['DB_NAME']\n",
    "    DB_USER                = config['CLUSTER']['DB_USER']\n",
    "    DB_PASSWORD            = config['CLUSTER']['DB_PASSWORD']\n",
    "    DB_PORT                = config['CLUSTER']['DB_PORT']\n",
    "\n",
    "    IAM_ROLE_NAME          = config['IAM_ROLE']['IAM_ROLE_NAME']\n",
    "    IAM_POLICY_ARN         = config['IAM_ROLE']['IAM_POLICY_ARN']\n",
    "    ARN                    = config['IAM_ROLE']['ARN']\n",
    "\n",
    "    return DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, \\\n",
    "           DWH_CLUSTER_IDENTIFIER, DWH_REGION, \\\n",
    "           HOST, DB_NAME, DB_USER, DB_PASSWORD, DB_PORT, \\\n",
    "           IAM_ROLE_NAME, IAM_POLICY_ARN, ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_REGION</td>\n",
       "      <td>us-west-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HOST</td>\n",
       "      <td>dwhcluster.cbsjbxldkge8.us-west-2.redshift.ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DB_NAME</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DB_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IAM_POLICY_ARN</td>\n",
       "      <td>arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ARN</td>\n",
       "      <td>'arn:aws:iam::376450510082:role/dwhRole'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Param                                              Value\n",
       "0         DWH_CLUSTER_TYPE                                         multi-node\n",
       "1            DWH_NUM_NODES                                                  4\n",
       "2            DWH_NODE_TYPE                                          dc2.large\n",
       "3   DWH_CLUSTER_IDENTIFIER                                         dwhCluster\n",
       "4               DWH_REGION                                          us-west-2\n",
       "5                     HOST  dwhcluster.cbsjbxldkge8.us-west-2.redshift.ama...\n",
       "6                  DB_NAME                                           sparkify\n",
       "7                  DB_USER                                            dwhuser\n",
       "8              DB_PASSWORD                                           Passw0rd\n",
       "9                  DB_PORT                                               5439\n",
       "10           IAM_ROLE_NAME                                            dwhRole\n",
       "11          IAM_POLICY_ARN     arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n",
       "12                     ARN           'arn:aws:iam::376450510082:role/dwhRole'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWH_CLUSTER_TYPE, \\\n",
    "DWH_NUM_NODES, \\\n",
    "DWH_NODE_TYPE, \\\n",
    "DWH_CLUSTER_IDENTIFIER, \\\n",
    "DWH_REGION, \\\n",
    "HOST, \\\n",
    "DB_NAME, \\\n",
    "DB_USER, \\\n",
    "DB_PASSWORD, \\\n",
    "DB_PORT, \\\n",
    "IAM_ROLE_NAME, \\\n",
    "IAM_POLICY_ARN, \\\n",
    "ARN  \\\n",
    " = load_config()\n",
    "\n",
    "\n",
    "params = pd.DataFrame({\"Param\":\n",
    "                [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\",\n",
    "                 \"DWH_CLUSTER_IDENTIFIER\", \"DWH_REGION\",\n",
    "                 \"HOST\", \"DB_NAME\", \"DB_USER\", \"DB_PASSWORD\", \"DB_PORT\",\n",
    "                 \"IAM_ROLE_NAME\", \"IAM_POLICY_ARN\", \"ARN\"\n",
    "                ],\n",
    "              \"Value\":\n",
    "                [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, \n",
    "                 DWH_CLUSTER_IDENTIFIER, DWH_REGION,\n",
    "                 HOST, DB_NAME, DB_USER, DB_PASSWORD, DB_PORT, \n",
    "                 IAM_ROLE_NAME, IAM_POLICY_ARN, ARN\n",
    "                ]\n",
    "            })\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the config params to the LOGFILE\n",
    "for i in range(params.shape[0]):\n",
    "    logger.info('{}:  {}'.format(params.Param[i], params.Value[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AWS Params from separate config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_aws = configparser.ConfigParser()\n",
    "config_aws.read_file(open('aws.cfg'))\n",
    "\n",
    "AWS_KEY     = config_aws['AWS']['KEY']\n",
    "AWS_SECRET  = config_aws['AWS']['SECRET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clients for EC2, S3, IAM, and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                      region_name           = DWH_REGION,\n",
    "                      aws_access_key_id     = AWS_KEY,\n",
    "                      aws_secret_access_key = AWS_SECRET\n",
    "                     )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                     region_name           = DWH_REGION,\n",
    "                     aws_access_key_id     = AWS_KEY,\n",
    "                     aws_secret_access_key = AWS_SECRET\n",
    "                    )\n",
    "\n",
    "iam = boto3.client('iam',\n",
    "                    region_name           = DWH_REGION,\n",
    "                    aws_access_key_id     = AWS_KEY,\n",
    "                    aws_secret_access_key = AWS_SECRET\n",
    "                   )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                         region_name           = DWH_REGION,\n",
    "                         aws_access_key_id     = AWS_KEY,\n",
    "                         aws_secret_access_key = AWS_SECRET\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('1.1 Creating a new IAM Role')\n",
    "    logger.info('Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "        Path                     = '/',\n",
    "        RoleName                 = IAM_ROLE_NAME,\n",
    "        Description              = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument = json.dumps(\n",
    "            {'Statement' : [{'Action'    : 'sts:AssumeRole',\n",
    "                             'Effect'    : 'Allow',\n",
    "                             'Principal' : {'Service': 'redshift.amazonaws.com'}\n",
    "                            }],\n",
    "             'Version'   : '2012-10-17'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 Attaching Policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('1.2 Attaching Policy')\n",
    "iam.attach_role_policy(RoleName = IAM_ROLE_NAME,\n",
    "                       PolicyArn = IAM_POLICY_ARN\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::376450510082:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "print('1.3 Get the IAM role ARN')\n",
    "roleArn = iam.get_role(RoleName = IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)\n",
    "logger.info('New IAM Role ARN:  {}'.format(roleArn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RedShift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ClusterAlreadyExists) when calling the CreateCluster operation: Cluster already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        # parameters for hardware\n",
    "        ClusterType        = DWH_CLUSTER_TYPE,\n",
    "        NodeType           = DWH_NODE_TYPE,\n",
    "        NumberOfNodes      = int(DWH_NUM_NODES),\n",
    "        \n",
    "        # parameters for identifiers & credentials\n",
    "        DBName             = DB_NAME,\n",
    "        ClusterIdentifier  = DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername     = DB_USER,\n",
    "        MasterUserPassword = DB_PASSWORD,\n",
    "\n",
    "        #  parameter for role (to allow s3 access)\n",
    "        IamRoles           = [roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    logger.info('Create cluster successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the cluster to see its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>creating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-aa278fd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key         Value\n",
       "0  ClusterIdentifier  dwhcluster  \n",
       "1  NodeType           dc2.large   \n",
       "2  ClusterStatus      creating    \n",
       "3  MasterUsername     dwhuser     \n",
       "4  DBName             sparkify    \n",
       "5  VpcId              vpc-aa278fd2\n",
       "6  NumberOfNodes      4           "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pretty_Redshift_props(props):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        \n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \n",
    "                  \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data = x, columns = [\"Key\", \"Value\"])\n",
    "\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier = DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "dfClusterProps = pretty_Redshift_props(myClusterProps)\n",
    "dfClusterProps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAIT...keep pinging until the cluster is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the cluster props to the LOGFILE\n",
    "for i in range(dfClusterProps.shape[0]):\n",
    "    logger.info('{}:  {}'.format(dfClusterProps.Key[i], dfClusterProps.Value[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting... 1 minutes\n",
      "waiting... 2 minutes\n",
      "waiting... 3 minutes\n",
      "waiting... 4 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.cbsjbxldkge8.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-aa278fd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  sparkify                                                                               \n",
       "5  {'Address': 'dwhcluster.cbsjbxldkge8.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-aa278fd2                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bClusterAvailable = False\n",
    "nMinutes = 0\n",
    "\n",
    "while True:\n",
    "    time.sleep(60)\n",
    "    nMinutes += 1\n",
    "    print(\"waiting... {} minutes\".format(nMinutes))\n",
    "\n",
    "    # then check the status\n",
    "    myClusterProps = redshift.describe_clusters(ClusterIdentifier = DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "    \n",
    "    if  myClusterProps['ClusterStatus'] == 'available':\n",
    "        bClusterAvailable = True\n",
    "        logger.info('ClusterStatus:  available')\n",
    "        logger.info('time to spin cluster:  {} minutes'.format(nMinutes))\n",
    "        break\n",
    "    \n",
    "    if nMinutes >= 7:\n",
    "        print(\"7 minute time limit reached\")\n",
    "        logger.info('7 minute time limit reached')\n",
    "        break\n",
    "    \n",
    "# cluster should be available now, OR the 7 minute limit has passed\n",
    "pretty_Redshift_props(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the HOST and role ARN to the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOST ::  dwhcluster.cbsjbxldkge8.us-west-2.redshift.amazonaws.com\n",
      "ARN  ::  arn:aws:iam::376450510082:role/dwhRole\n",
      "Saved to config file:   dwh.cfg\n"
     ]
    }
   ],
   "source": [
    "if bClusterAvailable:\n",
    "    HOST = myClusterProps['Endpoint']['Address']\n",
    "    ARN  = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "    print(\"HOST :: \", HOST)\n",
    "    print(\"ARN  :: \", ARN)\n",
    "\n",
    "    config['CLUSTER']['HOST'] = HOST\n",
    "    config['IAM_ROLE']['ARN'] = \"\\'{}\\'\".format(ARN)\n",
    "\n",
    "    with open(CONFIG_FILE, 'w') as configfile:\n",
    "        config.write(configfile)\n",
    "        print(\"Saved to config file:  \", CONFIG_FILE)\n",
    "        \n",
    "    logger.info('HOST:  {}'.format(HOST))\n",
    "    logger.info('ARN:   {}'.format(ARN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Cluster is Live!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open an incoming TCP port to access the cluster endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-6a554720')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id = myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName  = defaultSg.group_name,\n",
    "        CidrIp     = '0.0.0.0/0',\n",
    "        IpProtocol = 'TCP',\n",
    "        FromPort   = int(DB_PORT),\n",
    "        ToPort     = int(DB_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    logger.info('Opened TCP port on cluster endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you can connect to the cluster/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host=dwhcluster.cbsjbxldkge8.us-west-2.redshift.amazonaws.com dbname=sparkify user=dwhuser password=Passw0rd port=5439\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn_string = \"host={} dbname={} user={} password={} port={}\"\n",
    "    conn_string = conn_string.format(*config['CLUSTER'].values())\n",
    "    conn = psycopg2.connect( conn_string )\n",
    "    cur = conn.cursor()\n",
    "    print(conn_string)\n",
    "    logger.info(conn_string)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "finally:\n",
    "    logger.info('connected to database:  {}'.format(DB_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Ready for ETL...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run the ETL scripts...\n",
    ">\n",
    "> **...**  \n",
    "> **...   create_tables.py**  \n",
    "> **...   etl.py**  \n",
    "> **...**  \n",
    ">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Shutdown Cluster & Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/test-20190527.log'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mylib\n",
    "mylib.log_file_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the logger just in case I've gone past midnight, and into the next date\n",
    "# mylib.reset_logger()\n",
    "logger.info('Shutting down Cluster...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.cbsjbxldkge8.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-aa278fd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  deleting                                                                               \n",
       "3  dwhuser                                                                                \n",
       "4  sparkify                                                                               \n",
       "5  {'Address': 'dwhcluster.cbsjbxldkge8.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-aa278fd2                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift.delete_cluster( ClusterIdentifier = DWH_CLUSTER_IDENTIFIER, \n",
    "                         SkipFinalClusterSnapshot = True )\n",
    "\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier = DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "pretty_Redshift_props(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAIT... keep pinging until the cluster is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting... 1 minutes\n",
      "waiting... 2 minutes\n",
      "waiting... 3 minutes\n",
      "waiting... 4 minutes\n",
      "waiting... 5 minutes\n",
      "waiting... 6 minutes\n",
      "An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found.\n",
      "Meaning the Cluster was successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "bClusterDeleted = False\n",
    "nMinutes = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "        nMinutes += 1\n",
    "        print(\"waiting... {} minutes\".format(nMinutes))\n",
    "\n",
    "        # then check the status\n",
    "        myClusterProps = redshift.describe_clusters(ClusterIdentifier = DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "\n",
    "        if nMinutes >= 10:\n",
    "            print(\"10 minute time limit reached. Cluster may not have been deleted yet.\")\n",
    "            break\n",
    "\n",
    "        if  myClusterProps['ClusterStatus'] == 'deleting':\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    bClusterDeleted = True\n",
    "    print(e)\n",
    "    print(\"Meaning the Cluster was successfully deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bClusterDeleted:\n",
    "    iam.detach_role_policy(RoleName = IAM_ROLE_NAME, \n",
    "                           PolicyArn = IAM_POLICY_ARN)\n",
    "    iam.delete_role(RoleName = IAM_ROLE_NAME)\n",
    "\n",
    "    logger.info('===[  Cluster Deleted  ]===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "332.653px",
    "left": "1052.35px",
    "right": "20px",
    "top": "120px",
    "width": "361.431px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
